{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d82781b-7181-4075-9b07-a6d249fdda0e",
   "metadata": {},
   "source": [
    "# NLP Analysis of google reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc4296-64af-4954-b779-2492127a4b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97882b9-8419-4419-b649-be883ccd9ea8",
   "metadata": {},
   "source": [
    "## Import and clean df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c8348a-246a-4001-bab2-cf6694346fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv(\"../raw_data/merged_reviews_5_!2.csv\")\n",
    "merged_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf05bf1-a84e-4794-a674-a1398be6e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_merged_df = merged_df.drop(columns=['Unnamed: 0', 'review_count', 'rating'])\n",
    "cleaned_merged_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df7cab-bfff-45dc-b3c5-d33f22e63fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51d72bb-dd96-4a32-a2f6-5d897d391c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_merged_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008284f3-6322-448c-836e-166e9d2578f2",
   "metadata": {},
   "source": [
    "### proportion of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be55080-9969-4793-a811-b8fcccb149bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_proportions(df):\n",
    "    rating_prop_df = pd.DataFrame\\\n",
    "    ((df.comment_ratings.value_counts()/df.shape[0])*100)\\\n",
    "    .rename(columns = {'comment_ratings':'proportion'}).sort_index(ascending=False) #calculate percentage, rename column and sort index\n",
    "\n",
    "    rating_prop_df.index.names = ['ratings'] # rename index\n",
    "\n",
    "    rating_prop_df.proportion = rating_prop_df.proportion.map(lambda x: round(x)) # round % figures\n",
    "    \n",
    "    return rating_prop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355b3b5-9605-457e-9142-c8e58ad9d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_proportions(cleaned_merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e666931-04d4-4bce-9ffa-ab6a35dd425a",
   "metadata": {},
   "source": [
    "### how many reviews originally in portuguese?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19354e20-fa8b-4e23-8efa-7a9c56a134e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_merged_df.comment_comments.map(lambda x: 1 if str(x.find(\" pelo\")).isdigit()==True else 0).sum() #how many reviews translated into portuguese?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6d01e-8923-4363-861c-d59e786bbb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_merged_df['in_portuguese?'] = cleaned_merged_df.comment_comments.map(lambda x: 1 if str(x.find(\" pelo\")).isdigit()==True else 0) #create a new column to say which columns are portguese"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73035a40-aa2a-4b9f-8cb5-2323c789f315",
   "metadata": {
    "tags": []
   },
   "source": [
    "### proportion of ratings without translated portuguese reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f702c21-34f8-471e-850f-b76c0d042da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_reviews_df = cleaned_merged_df[cleaned_merged_df['in_portuguese?'] == 0] # reviews only in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f2d2d-43a9-490d-8da7-b7ad986d0e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_proportions(english_reviews_df) #proportion almost the same as the df including translated portuguese reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4543e34-fbcf-4c04-9666-7bd7f7b3416a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### how many reviews incomplete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362874ef-ec45-49a2-aea8-f48b089f15cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_merged_df.comment_comments.map(lambda x: 1 if str(x.find(\"…More\")).isdigit()==True else 0).sum() #how many reviews translated into portuguese?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1875700-0679-4046-9939-4117422e8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_merged_df['unfinished?'] = cleaned_merged_df.comment_comments.map(lambda x: 1 if str(x.find(\"…More\")).isdigit()==True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9949d748-f5b2-4a59-968c-a58f4c923a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ded41f-d001-497c-a6b3-3098f2239e02",
   "metadata": {},
   "source": [
    "### splitting reviews by complete/incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d57576d-c93b-4d32-9506-3adc96614dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_reviews_df = cleaned_merged_df[cleaned_merged_df['unfinished?'] == 0]\n",
    "incomplete_reviews_df = cleaned_merged_df[cleaned_merged_df['unfinished?'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cfb816-a2b4-47cb-8b18-d75f24c1794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_proportions(complete_reviews_df) #proportion almost the same as the df including translated portuguese reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57828a3-8eb2-48d6-a824-1b1584e846c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61422856-7c6d-4b4f-99f9-588ffb009339",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "        if len(incomplete_reviews_df.comment_comments.iloc[i]) < 100:\n",
    "            print(incomplete_reviews_df.comment_comments.iloc[i])  \n",
    "            print()\n",
    "            \n",
    "## most reviews even the incomplete short ones appear to give useful information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da412c3-8965-4639-a6e7-bf44b794f940",
   "metadata": {},
   "source": [
    "## NLP preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bf8ffb-b65d-44ee-b3ba-d480181765c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, list_form=False):\n",
    "    \"\"\"clean's text for NLP. If list_form set to False returns string otherwise returns list, by default set to False\"\"\"\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, ' ') # Remove Punctuation\n",
    "        \n",
    "    lowercased = text.lower() # Lower Case\n",
    "    \n",
    "    #unaccented_string = unidecode.unidecode(lowercased) # remove accents\n",
    "    \n",
    "    tokenized = word_tokenize(lowercased) # Tokenize\n",
    "    \n",
    "    words_only = [word for word in tokenized if word.isalpha()] # Remove numbers\n",
    "    \n",
    "    #    stop_words = set(stopwords.words('english')) # Make stopword list\n",
    "    #    without_stopwords = [word for word in words_only if not word in stop_words] # Remove Stop Words - better results when not removing stop words\n",
    "    \n",
    "    if list_form == True:\n",
    "        return words_only\n",
    "    else:\n",
    "        return \" \".join(words_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffba985-c287-4ed6-a6fe-7e5ab13f16fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_merged_df['clean_comment'] = cleaned_merged_df['comment_comments'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7c37a-c3c9-4a40-a674-11d5eea6ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f618ca9-862b-403c-ac2e-cf2db61fa9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_merged_df.tail(1).comment_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c72c5b-f2a0-4e6f-b5bc-0fb57f30cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_reviews_df['clean_comment'] = english_reviews_df['comment_comments'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61f34af-fc7a-4d02-89de-a8541518624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_reviews_df['clean_comment'] = complete_reviews_df['comment_comments'].apply(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc6d7c-5b85-43f6-b0bc-9fb4c0947ae3",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9097db4b-d796-4001-96aa-f3d3b653c774",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_merged_df['good_bad_review'] = cleaned_merged_df.comment_ratings.map(lambda x: 1 if x >=4.0 else 0)\n",
    "reviews_model_df = cleaned_merged_df[['clean_comment', 'good_bad_review']]\n",
    "reviews_model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d9f5d-8b62-4962-ad24-32437c7b0a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_reviews_df['good_bad_review'] = english_reviews_df.comment_ratings.map(lambda x: 1 if x >=4.0 else 0)\n",
    "en_reviews_model_df = english_reviews_df[['clean_comment', 'good_bad_review']]\n",
    "en_reviews_model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab71fe-4305-4d22-b110-7a0b1303ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_reviews_df['good_bad_review'] = complete_reviews_df.comment_ratings.map(lambda x: 1 if x >=4.0 else 0)\n",
    "complete_reviews_model_df = complete_reviews_df[['clean_comment', 'good_bad_review']]\n",
    "complete_reviews_model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cbfe5e-6483-403a-9993-a449ec7182f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89869727-be1c-4420-a085-eff145ce7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca464b2-324e-4977-a274-0dc4663e558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression()),\n",
    "])\n",
    "\n",
    "# Set parameters to search\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1,1), (2,2)),\n",
    "     'logreg__C': (0.01,1,10,100,1000)\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, \n",
    "                           verbose=1, scoring = \"f1\", cv=5)\n",
    "\n",
    "grid_search.fit(en_reviews_model_df['clean_comment'], en_reviews_model_df['good_bad_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd386c28-4181-4e84-9a59-e7fb84223da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1caf882-0c14-4458-bdcd-2499fc0585c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f636602-1b65-429a-959c-45eeaa1c2912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "reviews_model_df = en_reviews_model_df.sample(frac = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews_model_df['clean_comment'], reviews_model_df['good_bad_review'], random_state=42)\n",
    "\n",
    "\n",
    "# create bag-of-words with weights using tfid vectoriser\n",
    "# strip accents and remove stop words during vectorisation\n",
    "tf=TfidfVectorizer(strip_accents = 'ascii', ngram_range=(1, 2))\n",
    "\n",
    "# transform and fit the training set with vectoriser\n",
    "X_train_tf = tf.fit_transform(X_train)\n",
    "# transform the test set with vectoriser\n",
    "X_test_tf = tf.transform(X_test)\n",
    "\n",
    "\n",
    "# create logistic regression model\n",
    "logreg = LogisticRegression(verbose=0, random_state=42, penalty='l2', solver='newton-cg', C=10)\n",
    "# train model on  vectorised training data\n",
    "model = logreg.fit(X_train_tf, y_train)\n",
    "# evaluate model performance on the test set\n",
    "pred = model.predict(X_test_tf)\n",
    "metrics.f1_score(y_test, pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31907289-3dc0-4917-b099-be3a106256ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9c3059-0a0e-48fb-af08-f5e5223e1e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf960ea-0f6f-44a1-b61d-f7e61e3ea958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import lime\n",
    "import sklearn.ensemble\n",
    "from __future__ import print_function\n",
    "from lime import lime_text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# converting the vectoriser and model into a pipeline\n",
    "# this is necessary as LIME takes a model pipeline as an input\n",
    "c = make_pipeline(tf, model)\n",
    "\n",
    "# saving a list of strings version of the X_test object\n",
    "ls_X_test= list(X_test)\n",
    "\n",
    "# saving the class names in a dictionary to increase interpretability\n",
    "class_names = {0: 'bad review', 1:'good review'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e1bee-76d9-4203-ac8d-970dff85e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the LIME explainer\n",
    "# add the class names for interpretability\n",
    "LIME_explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "# choose a random single prediction\n",
    "idx = 309\n",
    "# explain the chosen prediction \n",
    "# use the probability results of the logistic regression\n",
    "# can also add num_features parameter to reduce the number of features explained\n",
    "LIME_exp = LIME_explainer.explain_instance(ls_X_test[idx], c.predict_proba)\n",
    "# print results\n",
    "print('Document id: %d' % idx)\n",
    "print('Review: ', ls_X_test[idx])\n",
    "print('Probability good review =', c.predict_proba([ls_X_test[idx]]).round(3)[0,1])\n",
    "print('True class: %s' % class_names.get(list(y_test)[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdecd7f-c463-41d4-bc8d-8edffa772582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print class names to show what classes the viz refers to\n",
    "print(\"1 = good review, 0 = bad review\")\n",
    "# show the explainability results with highlighted text\n",
    "LIME_exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcb53fa-bd85-4d93-9a0b-dad66c6083d2",
   "metadata": {},
   "source": [
    "## Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c99b1-0493-4a50-a690-73da947be228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8344dec-6c3d-4a90-b15f-ffc11687aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stop_words = set(stopwords.words('english')) # Make stopword list\n",
    "\n",
    "# Tuned TFidfvectorizer\n",
    "def Tfidf_fit(series):\n",
    "    for i in range(1,4):\n",
    "        vec = TfidfVectorizer(ngram_range = (i,i), stop_words=stop_words).fit(series)\n",
    "        return vec\n",
    "\n",
    "def transform_create_list(series):\n",
    "    vectors = Tfidf_fit(series).transform(series) # Transform text to vectors\n",
    "\n",
    "    sum_tfidf = vectors.sum(axis=0) # Sum of tfidf weighting by word\n",
    "\n",
    "    tfidf_list = [(word, sum_tfidf[0, idx]) for word, idx in     Tfidf_fit(series).vocabulary_.items()]  # Get the word and associated weight\n",
    "\n",
    "    sorted_tfidf_list =sorted(tfidf_list, key = lambda x: x[1], reverse=True)  # Sort\n",
    "\n",
    "    return sorted_tfidf_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5dc1c2-453d-480e-800e-db76cfc56827",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_fit(reviews_model_df.clean_comment)\n",
    "transform_create_list(reviews_model_df.clean_comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e2f67-cabf-43e2-acd4-76dffcca057a",
   "metadata": {},
   "source": [
    "### Word Cloud & N_Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b5d687-3893-41ff-b3bd-2ed893e869c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text): \n",
    "     tokenized = word_tokenize(text)\n",
    "     stop_words = set(stopwords.words('english')) # Make stopword list\n",
    "     with_stopwords = \" \".join([word for word in tokenized if not word in stop_words]) # Remove Stop Words - better results when not removing stop words\n",
    "     return with_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b537298-9b87-4b56-bacd-8b1520a06648",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_reviews_model_df.clean_comment = en_reviews_model_df.clean_comment.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ac2d22-8613-4f16-b825-02e389cae610",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_reviews_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0303f-5805-4063-95f7-15aaedd18cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(review for review in en_reviews_model_df.clean_comment.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555c1323-5896-46d0-bfbd-b30a0f94b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7163b87d-29d0-488e-8fff-8a465b84b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd3a3ce-3a75-41da-83cb-d9478a35bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa78138d-d429-4d6b-a9a6-86329b0d94b3",
   "metadata": {},
   "outputs": [],
   "source": [
    " from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import wordcloud\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 9]\n",
    "\n",
    "def create_ngrams(token_list, nb_elements):\n",
    "    \"\"\"\n",
    "    Create n-grams for list of tokens. Parameters: token_list : list of strings, nb_elements : number of elements in the n-gram\n",
    "    Returns: Generator, generator of all n-grams\n",
    "    \"\"\"\n",
    "    ngrams = zip(*[token_list[index_token:] for index_token in range(nb_elements)])\n",
    "    return (\" \".join(ngram) for ngram in ngrams)\n",
    "\n",
    "\n",
    "def frequent_words(list_words, ngrams_number=1, number_top_words=10):\n",
    "    \"\"\"\n",
    "    Create n-grams for list of tokens. Parameters: ngrams_number : int, number_top_words : int, output dataframe length\n",
    "    Returns. DataFrame, Dataframe with the entities and their frequencies.\n",
    "    \"\"\"\n",
    "    frequent = []\n",
    "    if ngrams_number == 1:\n",
    "        pass\n",
    "    elif ngrams_number >= 2:\n",
    "        list_words = create_ngrams(list_words, ngrams_number)\n",
    "    else:\n",
    "        raise ValueError(\"number of n-grams should be >= 1\")\n",
    "    counter = Counter(list_words)\n",
    "    frequent = counter.most_common(number_top_words)\n",
    "    return frequent\n",
    "\n",
    "\n",
    "def make_word_cloud(text_or_counter, stop_words=None):\n",
    "    if isinstance(text_or_counter, str):\n",
    "        word_cloud = wordcloud.WordCloud(stopwords=stop_words).generate(text_or_counter)\n",
    "    else:\n",
    "        if stop_words is not None:\n",
    "            text_or_counter = Counter(word for word in text_or_counter if word not in stop_words)\n",
    "        word_cloud = wordcloud.WordCloud(stopwords=stop_words).generate_from_frequencies(text_or_counter)\n",
    "    plt.imshow(word_cloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3c9a9d-29f2-4e1c-a79f-d9d9ef099a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_word_cloud(token_list, stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600512c0-cec4-4b07-8dd4-ff4fced30bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_words(token_list, ngrams_number=1, number_top_words=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c9a0d-1cdc-48b6-9e49-2c0133b3d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_words(token_list, ngrams_number=2, number_top_words=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7461d92e-aa9b-4948-881c-b5a118249c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_words(token_list, ngrams_number=3, number_top_words=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aaa013-24a0-4292-a7e4-0f8a4caad45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18060d89-a2a5-4493-86a5-7205aea1c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "reviews_model_df = en_reviews_model_df.sample(frac = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews_model_df['clean_comment'], reviews_model_df['good_bad_review'], random_state=42)\n",
    "\n",
    "\n",
    "# create bag-of-words with weights using tfid vectoriser\n",
    "# strip accents and remove stop words during vectorisation\n",
    "tf=TfidfVectorizer(strip_accents = 'ascii', ngram_range=(1, 1))\n",
    "\n",
    "# transform and fit the training set with vectoriser\n",
    "X_train_tf = tf.fit_transform(X_train)\n",
    "# transform the test set with vectoriser\n",
    "X_test_tf = tf.transform(X_test)\n",
    "\n",
    "\n",
    "# create logistic regression model\n",
    "logreg = LogisticRegression(verbose=0, random_state=42, penalty='l2', solver='newton-cg', C=10)\n",
    "# train model on  vectorised training data\n",
    "model = logreg.fit(X_train_tf, y_train)\n",
    "# evaluate model performance on the test set\n",
    "pred = model.predict(X_test_tf)\n",
    "metrics.f1_score(y_test, pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "652f7886-a42c-45ab-b433-d90f59968019",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12014/2927401368.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# sampling data from the training and test set to reduce time-taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mX_test_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_tf' is not defined"
     ]
    }
   ],
   "source": [
    "# importing SHAP\n",
    "import shap\n",
    "\n",
    "# sampling data from the training and test set to reduce time-taken\n",
    "X_train_sample = shap.sample(X_train_tf, 100)\n",
    "X_test_sample = shap.sample(X_test_tf, 20)\n",
    "\n",
    "# creating the KernelExplainer using the logistic regression model and training sample\n",
    "SHAP_explainer = shap.KernelExplainer(model, X_train_sample)\n",
    "# calculating the shap values of the test sample using the explainer \n",
    "shap_vals = SHAP_explainer.shap_values(X_test_sample)\n",
    "\n",
    "# converting the test samples to a dataframe \n",
    "# this is necessary for non-tabular data in order for the visualisations \n",
    "# to include feature value\n",
    "colour_test = pd.DataFrame(X_test_sample.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86da5b0-1d94-4fe1-903b-0371ce4bcb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_vals, colour_test, feature_names=tf.get_feature_names(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8bcdb5-a040-4dbc-9577-528bfbf4dc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
